<!DOCTYPE html>
<html lang="en-us"><head>
  <meta charset="utf-8">
  <title>Audio Fingerprinting: A Quick Startup guide</title>

  <!-- mobile responsive meta -->
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="A personal website and blog that features my latest works.">
  <meta name="author" content="Roshaan Siddiqui">
  <meta name="generator" content="Hugo 0.74.2" />

  <!-- plugins -->
  
  <link rel="stylesheet" href="/plugins/bootstrap/bootstrap.min.css">
  
  <link rel="stylesheet" href="/plugins/themify-icons/themify-icons.css">
  

  <!-- Main Stylesheet -->
  
  <link rel="stylesheet" href="/scss/style.css" media="screen">

  <!--Favicon-->
  <link rel="shortcut icon" href="/images/roshaan.png" type="image/x-icon">
  <link rel="icon" href="/images/roshaan.png" type="image/x-icon">

</head><body>
<!-- preloader start -->
<div class="preloader">
  
  <img src="/images/loading1.svg" alt="preloader">
  
</div>
<!-- preloader end -->

	<div id="particles-js"></div>
	<!-- navigation -->
<header class="sticky-top bg-black">
  <div class="container">
    
    <nav class="navbar navbar-expand-lg navbar-dark bg-transparent">
      <a class="navbar-brand" href="/"><img style="height: 50px; max-width:100%;" 
          src="/images/logo.png" alt="Hi! I&#39;m Roshaan ü§ì"></a>
      <button class="navbar-toggler border-0" type="button" data-toggle="collapse" data-target="#navigation">
        <i class="ti-menu text-white"></i>
      </button>

      <div class="collapse navbar-collapse text-center" id="navigation">
        <ul class="navbar-nav mx-auto">
          

          
          <li class="nav-item"><a class="nav-link" href="/#home">home</a>
          </li>
          
          <li class="nav-item"><a class="nav-link" href="/#about">about</a>
          </li>
          
          <li class="nav-item"><a class="nav-link" href="/#project">project</a>
          </li>
          
          <li class="nav-item"><a class="nav-link" href="/#blog">blog</a>
          </li>
          
          <li class="nav-item"><a class="nav-link" href="/#contact">contact</a>
          </li>
          
          
          <li class="nav-item">
            
            
          </li>
        </ul>

        
        <!-- navigation button -->
        <a href="https://roshaansiddiqui.com/Resume2020.pdf" target = "_blank"
          class="btn btn-primary ml-lg-4">View Resume</a>
        
      </div>
    </nav>
  </div>
</header>
<!-- /navigation -->
	<section class="section">
  <div class="container text-left text-sm-center">
    <h2>Audio Fingerprinting: A Quick Startup guide</h2>
  </div>
</section>
	

<section class="section pt-0">
  <div class="container">
    <div class="row">
      <article class="col-lg-8 col-md-10 mx-auto" data-file="/blogs/audio-fingerprinting/" data-target="article">
        <div class="text-center">
          <img src="/images/blogs/waves.jpg" alt="" class="img-fluid mb-4"> 
          <ul class="list-inline mb-3">
            <li class="list-inline-item"><i class="text-primary ti-calendar mr-2"></i>20 Jul, 2020</li>
            <li class="list-inline-item"><i class="text-primary ti-time mr-2"></i><span class="eta"></span> read</li>
            
          </ul>
          
        </div>
        <div class="content mt-5">
          <h3 id="audio-fingerprinting-a-quick-startup-guide">Audio Fingerprinting: A Quick Startup guide</h3>
<br>
<h4 id="what-is-audio-fingerprinting">What is Audio Fingerprinting?</h4>
<p>Audio fingerprinting has been widely used for music and sound identification. This technology enables a user to record as little as 2 seconds of an audio signal and can identify the original sound that matches with the signal with ~95.6% certainty. This technology has also enabled various avenues of research such as identifying birds in the wild by using their unique acoustic signatures and help to mitigate privacy concerns for products like Amazon Echo, and Apple‚Äôs Siri that use voice commands to turn their services on.</p>
<p>Audio fingerprinting represents a digital summary of an audio signal. The digital summary is created by identifying the most prominent parts of the audio signal. This is traditionally done by creating a spectrogram of the signal and then running a peak identification algorithm on it to extract the peaks. After this, surrounding peaks are used to create a unique hash signature which is then stored in a database.</p>
<h5 id="for-a-thorough-review-of-this-topic-i-would-highly-reccomend-the-following-websites">For a thorough review of this topic, I would highly reccomend the following websites:</h5>
<ol>
<li><a href="https://www.youtube.com/watch?v=WhXgpkQ8E-Q&amp;t=2699s">A live example and lecture about audio fingerprinting</a></li>
<li><a href="http://coding-geek.com/how-shazam-works/">A thorough guide for how Shazam Works</a></li>
<li><a href="https://jackschaedler.github.io/circles-sines-signals/index.html">An interactive guide to understanding signal processing terminology</a></li>
<li><a href="https://drive.google.com/file/d/1zxpGj5dbVAlt-Y2iwfL-G3xqZkdRywgm/view">Shazam&rsquo;s Audio Fingerprinting Research Paper</a></li>
</ol>
<h3 id="getting-started-with-audio-fingerprinting">Getting Started with Audio Fingerprinting</h3>
<p>Even if you do not know much about audio fingerprinting, dont worry, you can still get started by using an opensource project called <strong>Dejavu</strong>. I would highly reccomend reading this article (Audio Fingerprinting with Python and Numpy)[https://willdrevo.com/fingerprinting-and-audio-recognition-with-python/] written by the author of Dejavu. It talks about the internal functions of the algorithm.</p>
<p>From here, simply follow the ReadMe in the Github repository which will guide you to configure your setup with Docker.</p>
<h3 id="my-experience-using-dejavu">My experience using Dejavu</h3>
<p>I downloaded 15 30-minute segments from CBS 13, TV station based in Portland, Maine. After that, I split the 30 minute videos into 3 equal 10 minute chunks using Ffmpeg&rsquo;s audio module with Python. Then, I manually went into the videos and extracted small segments where the transitions came up. I fingerprinted these transitions into the Dejavu database so we can use these for identification purposes later. After this, I ran the Audio Identification algorithm on each 10 minute video segment and the algorithm gave me a time of where it believes the transition started in the 10 minute segment chunks. Finally, I manually cross checked the algorithm‚Äôs time offsets with the actual offsets to measure its accuracy.</p>
<blockquote>
<p>These were my results when I ran the algorithm on the segments</p>
</blockquote>
<table>
<thead>
<tr>
<th><strong>Video Segments</strong></th>
<th><strong>Accuracy Of Identification</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Start</td>
<td>92.8%</td>
</tr>
<tr>
<td>Middle</td>
<td>64.2%</td>
</tr>
<tr>
<td>Ending</td>
<td>14.2%</td>
</tr>
</tbody>
</table>
<p>The algorithm identified the timing of the transitions in the beginning segments of the news data much better than it did compared to the middle and ending segments. The cause for such discrepancy might be in the fact that the transitions were slightly different throughout the news segments. One way to fix this would be  to identify unique transitions and put their fingerprints in the database. The algorithm also identified what kind of transition were identified. It almost always detected the sports transition as well as the weather report transition.</p>
<h5 id="shazams-founder-chris-barton-discussing-the-creation-of-the-algorithm"><strong>Shazam&rsquo;s Founder Chris Barton discussing the creation of the algorithm</strong></h5>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/O_iv702jj90" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<br>
<h4 id="sources">Sources</h4>
<ul>
<li>
<p>Drevo, Will. Audio Fingerprinting with Python and Numpy, 15 Nov. 2013, willdrevo.com/fingerprinting-and-audio-recognition-with-python/.</p>
</li>
<li>
<p>SLOANE, GARETT. ‚ÄúWhat Is Acoustic Fingerprinting‚Äù. Digiday, 29 Mar. 2016, digiday.com/media/what-is-acoustic-fingerprinting/.</p>
</li>
</ul>

        </div>
      </article>
    </div>
  </div>
</section>

<footer class="py-5">
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
        <ul class="list-inline social-icons mb-5">
          
          <li class="list-inline-item"><a href="https://github.com/roshaans"><i class="ti-github"></i></a></li>
          
          <li class="list-inline-item"><a href="https://www.linkedin.com/in/roshaan-siddiqui/"><i class="ti-linkedin"></i></a></li>
          
        </ul>
        <hr class="mx-auto border-default" style="width: 90px;">
        <p class="mt-5">Copyright ¬© 2020 Roshaan Siddiqui</p>
      </div>
    </div>
  </div>
</footer>


<!-- JS Plugins -->

<script src="/plugins/jQuery/jquery.min.js"></script>

<script src="/plugins/bootstrap/bootstrap.min.js"></script>

<script src="/plugins/particles/particles.min.js"></script>

<script src="/plugins/particles/stats.min.js"></script>

<script src="/plugins/reading-time/readingTime.min.js"></script>


<!-- Main Script -->

<script src="/js/script.min.js"></script>

<!-- google analitycs -->

<script>
  (function (i, s, o, g, r, a, m) {
    i['GoogleAnalyticsObject'] = r;
    i[r] = i[r] || function () {
      (i[r].q = i[r].q || []).push(arguments)
    }, i[r].l = 1 * new Date();
    a = s.createElement(o),
      m = s.getElementsByTagName(o)[0];
    a.async = 1;
    a.src = g;
    m.parentNode.insertBefore(a, m)
  })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
  ga('create', 'UA-173008301-1', 'auto');
  ga('send', 'pageview');
</script>
</body>

</html>